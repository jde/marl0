services:
  app:
    build:
      context: ./app
    depends_on:
      - kafka
      - postgres
      - memgraph
      - redis
      - minio
      - prometheus
      - grafana
    volumes:
      - ./app:/usr/src/app
    ports:
      - "4200:3000"
    environment:
      - NODE_ENV=development
    command: ["npm", "run", "dev"]

  ingestor:
    build:
      context: ./services/ingestor
    container_name: ingestor
    ports:
      - "3000:3000" # Prometheus metrics
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - default

  entity-extractor:
    build:
      context: ./services/entity-extractor
    container_name: entity-extractor
    ports:
      - "3001:3000" # Prometheus metrics
    depends_on:
      kafka:
        condition: service_healthy
      ingestor:
        condition: service_started
      local-llm:  
        condition: service_healthy
    networks:
      - default

  kafka:
    image: bitnami/kafka:latest
    ports:
      - "4292:9092"
    environment:
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/9092"]
      interval: 10s
      timeout: 5s
      retries: 10
      
  zookeeper:
    image: bitnami/zookeeper:latest
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "4218:2181"

  local-llm:
    image: ollama/ollama
    ports:
      - "11434:11434" # Ollama API default port
    volumes:
      - ${OLLAMA_DATA_DIR}:/root/.ollama
    environment:
      - OLLAMA_MODELS=/models
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ollama list > /dev/null 2>&1"]
      interval: 2s
      timeout: 5s
      retries: 300

  postgres:
    image: postgres:latest
    environment:
      POSTGRES_USER: youruser
      POSTGRES_PASSWORD: yourpass
      POSTGRES_DB: yourdb
    ports:
      - "4242:5432"
    volumes:
      - ${POSTGRES_DATA_DIR}:/var/lib/postgresql/data

  lancedb:
    build:
      context: ./services/lancedb
      dockerfile: Dockerfile
    ports:
      - "4280:8080"
    volumes:
      - ${LANCEDB_DATA_DIR}:/data

  memgraph:
    image: memgraph/memgraph-platform:latest
    ports:
      - "4287:7687"
      - "4201:3000" # Memgraph Lab UI
    volumes:
      - ${MEMGRAPH_DATA_DIR}:/var/lib/memgraph

  redis:
    image: redis:latest
    ports:
      - "4279:6379"
    volumes:
      - ${REDIS_DATA_DIR}:/data

  minio:
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "4202:9000"
      - "4203:9001"
    command: server /data --console-address ":9001"
    volumes:
      - ${MINIO_DATA_DIR}:/data

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "4204:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "4205:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ${GRAFANA_DATA_DIR}:/var/lib/grafana
    depends_on:
      - prometheus

  curl:
    image: curlimages/curl:latest
    entrypoint: ["sleep", "infinity"]
    networks:
      - default

  # Pull models at build time
  # Keep up to date with all models we want to use locally
  ollama-init:
    build:
      context: ./services/ollama-init
    volumes:
      - ${OLLAMA_DATA_DIR}:/root/.ollama
    environment:
      - OLLAMA_MODELS=/models